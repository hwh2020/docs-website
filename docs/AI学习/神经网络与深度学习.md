# 机器学习基础

------

## 机器学习概述

### 机器学习的三个基本要素



#### 模型

&emsp;&emsp;机器学习的样本为 $(\pmb{x},y)\in X\times Y$ . 假定 $x$ 和 $y$ 之间的映射关系存在一个真实映射函数 $y = g(\pmb{x})$ 或真实条件概率分布 $P_r(y|\pmb{x})$ 描述, 那么机器学习的目标就是找到一个模型来近似真实映射函数 $g(x)$ 或真实条件概率分布 $P_r(y|\pmb{x})$ .

&emsp;&emsp;其中,$\pmb{x}$ 是输入的特征向量, $y$ 是输出标签, $X$ 是输入空间(特征空间), $Y$ 是输出空间. 不同的机器学习任务主要区别在于输出空间不同, 在二分类问题中 $y= \lbrace +1,-1 \rbrace$ ,在C分类问题中 $y= \lbrace 1,2,\cdots ,C \rbrace$ ,而在回归问题中 $y=\mathbb{R}$​.

&emsp;&emsp;由于不清楚真实映射函数 $g(x)$ 或真实条件概率分布 $P_r(y|\pmb{x})$ 的具体形式,因而只能根据经验来假设一个函数集合$\mathcal{F}$(假设空间), 通过观察其在训练集 $\mathcal{D}$上的特性,从中选择一个理想的假设 $f^* \in \mathcal{F}$ . 其中  $\mathcal{F}=\lbrace f(\pmb{x};\theta) |\theta \in \mathbb{R}^D\rbrace$ ,里面的 $f(\pmb{x};\theta)$是参数$\theta$ 的函数,也称为模型.

---

##### 线性模型

$$
f(\pmb{x};\theta) =\pmb{\omega}^T\pmb{x}+b
$$

&emsp;&emsp;其中,$\pmb{\omega}$ 是权重向量,b是偏置值,参数$\theta$ 包含了$\pmb{\omega}$​与b.



##### 非线性模型

$$
f(\pmb{x};\theta) =\pmb{\omega}^T\phi(\pmb{x})+b
$$

&emsp;&emsp;其中,$\phi(\pmb{x})=[\phi_1(\pmb{x}),\phi_2(\pmb{x}),\cdots,\phi_K(\pmb{x})]^T$ 为$K$​个非线性基函数组成的向量.

---

##### 学习准则

&emsp;&emsp;一个好的模型$f(\pmb{x};\theta^\ast)$ 应该在所有$(\pmb{x},y)$的可能取值都与真实映射函数 $y = g(\pmb{x})$ 一致,即
$$
|f(\pmb{x};\theta^\ast)-y|<\epsilon,\qquad \forall(\pmb{x},y)\in X\times Y,
$$
或与真实条件概率分布 $P_r(y|\pmb{x})$ 一致,即
$$
|f_y(\pmb{x};\theta^\ast)-P_r(y|\pmb{x})|<\epsilon,\qquad \forall(\pmb{x},y)\in X\times Y,
$$
&emsp;&emsp;其中 $\epsilon$ 是一个很小的正数.模型$f(\pmb{x};\theta^*)$的好坏可以通过$\color{red}{期望风险 \mathcal{R}(\theta)}$​​​来衡量.即
$$
\mathcal{R}(\theta)=\mathbb{E}_{(\pmb{x},y)\sim P_r(\pmb{x},y)}\left[\mathcal{L}(y,f(\pmb{x};\theta))\right]
$$
&emsp;&emsp;其中$P_r(\pmb{x},y)$为真实数据分布, $\mathcal{L}(y,f(\pmb{x};\theta))$ 为损失函数, $\mathbb{E}_{x\sim p(x)}[f(x)]$ 表示期望. 由于$P_r(\pmb{x},y)$​​ 实际是不知道的,因而无法计算期望风险.但根据$\color{red}{大数定律}$,**当采集足够多的样本,样本均值就趋近于真实的期望**.即
$$
\mathbb{E}_{(\pmb{x},y)\sim P_r(\pmb{x},y)}[\mathcal{L}(y,f(\pmb{x};\theta))]\;\approx\;\frac{1}{N}\sum_{n=1}^N\mathcal{L}(y,f(\pmb{x};\theta))
$$

---

###### 损失函数

&emsp;&emsp;损失函数是计算模型预测值与真实标签之间的差异.

$\color{red}{0-1损失函数}$​


$$
\mathcal{L}(y,f(\pmb{x};\theta))=
   \begin{cases}
   0 \quad if\; y=f(\pmb{x};\theta)\\
   1 \quad if\; y\neq f(\pmb{x};\theta)
   \end{cases}\; =
   I(y\neq f(\pmb{x};\theta))
$$
   其中,$I(\cdot)$ 为指示函数,即$I(x)$中, $x$​ 为真返回1,为假返回0.

   缺点:数学性质不好,不连续且导数为0,难以优化.

---

$\color{red}{平方损失函数}$​
$$
\mathcal{L}(y,f(\pmb{x};\theta))=
\frac{1}{2}(y-f(\pmb{x};\theta))^2
$$
平方损失函数常用在预测标签$y$​为实数值的任务中,一般不适用于分类问题.

---

$\color{red}{交叉熵损失函数}$​

前提知识:

​	$\color{red}{自信息}$:表示一个随机事件所包含的信息量.一个随机事件发生的概率越高,其自信息就越低,反之亦然. 自信息$I(x)$为 
$$
I(x)=-log\;p(x)
$$
其对数底数可以为2,也可以为e或10.底数不同,自信息表示的单位也不同.


​	$\color{red}{熵}$:用来衡量一个随机事件的不确定性.当熵越高,则随机变量的信息就越多,反之亦然. 对于分布为$p(x)$的随机变量$X$,其熵$H(x)$​为自信息的数学期望,即
$$
\begin{align}
H(x) &=\mathbb{E}[I(x)]\\
&= \mathbb{E}[-log\;p(x)]\\
&=-\sum_{x\in X} p(x)\;log\;p(x)
\end{align}
$$



> [!note]
>
> 对于具有$N$种等可能状态的信息,每种状态的可能性是$p=\frac{1}{N}$​.那么编码该信息的最小编码长度为
> $$
> log_2N=-log_2\frac{1}{N}=-log_2\;p
> $$
> 为什么是$log_2N$ ? 这是因为1bit可以表示两种状态,那么$n$个bit可以表示$2^n$种状态,故$N$种状态的最小编码为$log_2N$​​.
>
> 
>
> 那么熵就是平均最小长度,即 
> $$
> H(p)=-\sum_i^N\;p(i)\;log_2\;p(i)
> $$



那么交叉熵就是指: 在真实分布$p$上使用估计的概率分布 $q$ 对信息进行编码的长度.






设在C分类的任务中,样本标签$\pmb{y}$是一个C维的 $\color{red}{one-hot 向量}$, 即当样本的标签为k时,那么标签向量$\pmb{y}$只有第k维的值为1,其余元素的值都为0;而$f_c(\pmb{x};\theta)$表示模型$f(\pmb{x};\theta)$​​​的输出向量的第c维.



那么标签的真实分布$\pmb{y}$和模型预测分布$f(\pmb{x};\theta)$​之间的交叉熵为:



$\color{red}{Hinge损失函数}$

## 线性模型







# 基础模型

## 前馈神经网络

## 卷积神经网络

## 循环神经网络

## 网络优化与正则化

## 注意力机制与外部记忆

## 无监督学习

## 模型独立的学习方式







# 进阶模型

## 概率图模型

## 深度信念网络

## 深度生成模型

## 深度强化学习

## 序列生成模型



# 常用符号表

| $ \mathbb{R}$ | 实数集 |
| ------------- | ------ |
|               |        |
|               |        |
|               |        |

