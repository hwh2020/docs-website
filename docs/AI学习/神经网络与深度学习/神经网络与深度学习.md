# 机器学习基础

------

## 机器学习概述

### 机器学习的三个基本要素



#### 模型

&emsp;&emsp;机器学习的样本为 $(\pmb{x},y)\in X\times Y$ . 假定 $x$ 和 $y$ 之间的映射关系存在一个真实映射函数 $y = g(\pmb{x})$ 或真实条件概率分布 $P_r(y|\pmb{x})$ 描述, 那么机器学习的目标就是找到一个模型来近似真实映射函数 $g(x)$ 或真实条件概率分布 $P_r(y|\pmb{x})$ .

&emsp;&emsp;其中,$\pmb{x}$ 是输入的特征向量, $y$ 是输出标签, $X$ 是输入空间(特征空间), $Y$ 是输出空间. 不同的机器学习任务主要区别在于输出空间不同, 在二分类问题中 $y= \lbrace +1,-1 \rbrace$ ,在C分类问题中 $y= \lbrace 1,2,\cdots ,C \rbrace$ ,而在回归问题中 $y=\mathbb{R}$​.

&emsp;&emsp;由于不清楚真实映射函数 $g(x)$ 或真实条件概率分布 $P_r(y|\pmb{x})$ 的具体形式,因而只能根据经验来假设一个函数集合$\mathcal{F}$(假设空间), 通过观察其在训练集 $\mathcal{D}$上的特性,从中选择一个理想的假设 $f^* \in \mathcal{F}$ . 其中  $\mathcal{F}=\lbrace f(\pmb{x};\theta) |\theta \in \mathbb{R}^D\rbrace$ ,里面的 $f(\pmb{x};\theta)$是参数$\theta$ 的函数,也称为模型.

---

##### 线性模型

$$
f(\pmb{x};\theta) =\pmb{\omega}^T\pmb{x}+b
$$

&emsp;&emsp;其中,$\pmb{\omega}$ 是权重向量,b是偏置值,参数$\theta$ 包含了$\pmb{\omega}$​与b.



##### 非线性模型

$$
f(\pmb{x};\theta) =\pmb{\omega}^T\phi(\pmb{x})+b
$$

&emsp;&emsp;其中,$\phi(\pmb{x})=[\phi_1(\pmb{x}),\phi_2(\pmb{x}),\cdots,\phi_K(\pmb{x})]^T$ 为$K$​个非线性基函数组成的向量.

---

#### 学习准则

&emsp;&emsp;一个好的模型$f(\pmb{x};\theta^\ast)$ 应该在所有$(\pmb{x},y)$的可能取值都与真实映射函数 $y = g(\pmb{x})$ 一致,即
$$
|f(\pmb{x};\theta^\ast)-y|<\epsilon,\qquad \forall(\pmb{x},y)\in X\times Y,
$$
或与真实条件概率分布 $P_r(y|\pmb{x})$ 一致,即
$$
|f_y(\pmb{x};\theta^\ast)-P_r(y|\pmb{x})|<\epsilon,\qquad \forall(\pmb{x},y)\in X\times Y,
$$
&emsp;&emsp;其中 $\epsilon$ 是一个很小的正数.模型$f(\pmb{x};\theta^*)$的好坏可以通过$\color{red}{期望风险 \mathcal{R}(\theta)}$​​​来衡量.即
$$
\mathcal{R}(\theta)=\mathbb{E}_{(\pmb{x},y)\sim P_r(\pmb{x},y)}\left[\mathcal{L}(y,f(\pmb{x};\theta))\right]
$$
&emsp;&emsp;其中$P_r(\pmb{x},y)$为真实数据分布, $\mathcal{L}(y,f(\pmb{x};\theta))$ 为损失函数, $\mathbb{E}_{x\sim p(x)}[f(x)]$ 表示期望. 由于$P_r(\pmb{x},y)$​​ 实际是不知道的,因而无法计算期望风险.但根据$\color{red}{大数定律}$,**当采集足够多的样本,样本均值就趋近于真实的期望**.即
$$
\mathbb{E}_{(\pmb{x},y)\sim P_r(\pmb{x},y)}[\mathcal{L}(y,f(\pmb{x};\theta))]\;\approx\;\frac{1}{N}\sum_{n=1}^N\mathcal{L}(y,f(\pmb{x};\theta))
$$

---

##### 损失函数

&emsp;&emsp;损失函数是计算模型预测值与真实标签之间的差异.

###### $\color{red}{0-1损失函数}$​


$$
\mathcal{L}(y,f(\pmb{x};\theta))=
   \begin{cases}
   0 \quad if\; y=f(\pmb{x};\theta)\\
   1 \quad if\; y\neq f(\pmb{x};\theta)
   \end{cases}\; =
   I(y\neq f(\pmb{x};\theta))
$$
   其中,$I(\cdot)$ 为指示函数,即$I(x)$中, $x$​ 为真返回1,为假返回0.

   缺点:数学性质不好,不连续且导数为0,难以优化.

---

###### $\color{red}{平方损失函数}$​

$$
\mathcal{L}(y,f(\pmb{x};\theta))=
\frac{1}{2}(y-f(\pmb{x};\theta))^2
$$
平方损失函数常用在预测标签$y$​为实数值的任务中,一般不适用于分类问题.

---

###### $\color{red}{交叉熵损失函数}$​

前提知识:

​	$\color{red}{自信息}$:表示一个随机事件所包含的信息量.一个随机事件发生的概率越高,其自信息就越低,反之亦然. 自信息$I(x)$为 
$$
I(x)=-log\;p(x)
$$

> [!NOTE]
>
> #### **直观理解**
>
> - 如果一个事件发生的概率很高（接近 1），那么这个事件的发生并不令人意外，它并没有带来太多“新信息”。
>   - 例如：“太阳从东边升起”是一个概率为 1 的事件，它的发生不会带来任何信息量，因此自信息为 0。
> - 如果一个事件发生的概率很低（接近 0），那么这个事件的发生会让人感到意外，它带来了更多的“新信息”。
>   - 例如：“今天下雨了”在沙漠地区是一个低概率事件，它的发生会带来很大的信息量。
>
> #### **数学解释**
>
> - 从公式 $I(x)=-log\;p(x)$ 可以看出：
>   - 当 $p(x)$ 接近 1 时，$log\;p(x)$ 接近 0，因此 $I(x)$ 接近 0。
>   - 当 $p(x)$ 接近 0 时，$log\;p(x)$ 会趋近于负无穷，因此 $I(x)$  会趋近于正无穷。

其对数底数可以为2,也可以为e或10.底数不同,自信息表示的单位也不同.


​	$\color{red}{熵}$:用来衡量一个随机事件的不确定性.当熵越高,则随机变量的信息就越多,反之亦然. 对于分布为$p(x)$的随机变量$X$,其熵$H(x)$​为自信息的数学期望,即
$$
\begin{align}
H(x) &=\mathbb{E}[I(x)]\\
&= \mathbb{E}[-log\;p(x)]\\
&= \sum_{x\in X} p(x)\; I(x)\\
&=-\sum_{x\in X} p(x)\;log\;p(x)
\end{align}
$$



> [!note]
>
> 对于具有$N$种等可能状态的信息,每种状态的可能性是$p=\frac{1}{N}$​.那么编码该信息的最小编码长度为
> $$
> n = log_2N=-log_2\frac{1}{N}=-log_2\;p
> $$
> 为什么是$log_2N$ ? 这是因为1bit可  以表示两种状态,那么$n$个bit可以表示$2^n$种状态,故$N$种状态的最小编码为$log_2N$​​.
>
> 那么熵就是平均最小长度,即 
> $$
> H(p)=-\sum_i^N\;p(i)\;log_2\;p(i)
> $$



那么交叉熵就是指: 在真实分布$p$上使用估计的概率分布 $q$​ 对信息进行编码的长度.
$$
\begin{align}
H(p,q)&=\mathbb{E}_p[-log\;q(x)]\\
&=-\sum_xp(x)log\;q(x)
\end{align}
$$



设在C分类的任务中,样本标签$\pmb{y}$是一个C维的 $\color{red}{one-hot 向量}$, 即当样本的标签为k时,那么标签向量$\pmb{y}$只有第k维的值为1,其余元素的值都为0; 那么$y_c$  就是分类类别为c的真实概率, 而$f_c(\pmb{x};\theta)$表示模型$f(\pmb{x};\theta)$​​​的输出向量的第c维.

那么标签的真实分布$\pmb{y}$和模型预测分布$f(\pmb{x};\theta)$​​之间的交叉熵为:
$$
\mathcal{L}(y,f(\pmb{x};\theta))=
-\sum_{c=1}^C\;y_c\;log\;f_c(\pmb{x},\theta)
$$
由于 $\pmb{y}$ 是 one-hot 向量, 故它们的交叉熵为:
$$
\mathcal{L}(y,f(\pmb{x};\theta))=-\;log\;f_y(\pmb{x},\theta)
$$

---

###### $\color{red}{Hinge损失函数}$

对于二分类问题, $y$ 和 $f(x,\theta)$ 取值为 {-1, +1}. 那么 hinge损失函数为:
$$
\mathcal{L}(y,f(\pmb{x};\theta))= max(0,1-y\;f(x,\theta))
$$
其中,  $y\;f(x,\theta)$ 称为分类间隔,表示预测值 与真实标签的一致性.

假如 真实标签是 +1, 预测标签是 + 0.2, 虽然样本正确分类, 但是分类间隔是+0.2,此时的损失为0.8

而另外一种情况是, 真实标签是 +1, 预测标签是 + 0.9, 样本正确分类, 此时损失是0.1

也就是说,如果损失 是大于 +1, 那么表示错误分类,损失是(0, 1)之间,那么是正确分类,同时还可以体现分类的间隔.

---

##### 风险最小化准则

前面提到, 期望风险可以衡量模型的好坏, 而经验风险可以近似于期望风险, 也就是说我们需要找到一组合适的参数 ${\theta}^*$​ 来使得 经验风险 最小.
$$
\Re(\theta)\approx\frac{1}{N}\sum_{n=1}^N\mathcal{L}(y,f(\pmb{x};\theta))\\
{\theta}^* = {arg}_{\theta}\; min\; R(\theta)
$$
其中 $arg\;min$ 表示使函数取得最小值的参数



既然如此,那么我们只需要找到一个参数$\theta$ 让经验风险最小即可不就行了吗?

并不是, 因为我们是无法得到无限的训练样本,且训练样本可能包含一定噪声. 所以这就很可能会造成模型在训练集表现很好,但是在其他数据错误率较高. 这称为$\color{red}{过拟合}$.

​	为了解决过拟合问题,我们需要对模型进行限制,不要过度地最小化经验风险.即在使经验风险最小化的基础上再引入参数的正则化惩罚,来对模型进行泛化. 这种叫做 $\color{red}{结构风险最小化}$​ . 关于正则化项后续会讲解.

​	与过拟合概念相反的是 欠拟合, 即模型在训练集上错误率比较高,不能很好地拟合训练数据.

---

#### 优化算法

​	在风险最小化准则下,如何找到最优的参数称为 最优化 问题. 而机器学习的训练过程 就是最优化问题的求解过程.

一般思路就是寻找合适的损失函数来构造一个关于 $\theta$  的凸函数。这样就可以寻找该函数的最小值（即损失函数最小化），从而寻找到最优的 $\theta$  。注意，$\theta$ 并不是一个变量，而是多个变量的集合。

> [!NOTE]
>
> 凸函数的定义
>
> 二阶导 $f''\geq 0$ , 在图像上，大致是向下凸的曲线。

有些情况，优化目标是非凸的，只能寻找局部最优解。

---

##### 梯度下降法

前提知识：导数，偏导，方向导数，梯度

- 导数：一元函数的导数是某一个点沿着x轴正方向的变化率，即如果 f’(x) >0，说明 f(x) 的函数值在 x 点沿 x 轴正方向是趋于增加的；如果 f’(x)<0 ，说明 f(x) 的函数值在x点沿x轴正方向是趋于减少的。
  $$
  f'(x_0)=\lim_{\Delta x \rightarrow 0}\frac{\Delta y}{\Delta x}
  =\lim_{\Delta x \rightarrow 0}\frac{f(x_0 + \Delta x)-f(x_0)}{\Delta x}
  $$

- 偏导：多元函数的偏导是某一个点沿着某一个坐标轴正方向的变化率。
  $$
  \frac{\partial f(x_0,x_1,\cdots,x_n)}{\partial x_j}=
  \lim_{\Delta x \rightarrow 0}\frac{\Delta y}{\Delta x}=
  \lim_{\Delta x \rightarrow 0}\frac{f(x_0,\cdots,x_j+\Delta x,\cdots,x_n)-f(x_0,\cdots,x_j,\cdots,x_n)}{\Delta x}
  $$

- 方向导数：函数沿着任意方向的变化率。
  $$
  \frac{\partial f(x_0,x_1,\cdots,x_n)}{\partial l}=
  \lim_{\rho \rightarrow 0}\frac{\Delta y}{\Delta x}=
  \lim_{\rho \rightarrow 0}\frac{f(x_0+\Delta x_0,\cdots,x_j+\Delta x_j,\cdots,x_n+\Delta x_n)-f(x_0,\cdots,x_j,\cdots,x_n)}{\rho}
  $$

​		$\rho = \sqrt{(\Delta x_0)^2+\cdots+(\Delta x_j)^2+\cdots+(\Delta x_n)^2}$​

- 梯度：梯度是一个向量，具有数值和方向，其数值是方向导数的最大值，方向是最大方向导数的方向。



梯度方向就是函数在变量空间某一点处所具有最大变化率的方向，那么沿着梯度方向的反方向就可以减小函数值，从而达到我们的优化目标。即梯度下降法
$$
\begin{align}
\theta_{t+1}&=\theta_t-\alpha\frac{\partial \Re_D(\theta)}{\partial \theta}\\
&=\theta_t-\alpha\frac{1}{N}\sum^{N}_{n=1}\frac{\partial \mathcal{L}(y,f(\pmb{x};\theta))}{\partial \theta}
\end{align}
$$
$\Re_D(\theta)$ 是训练集 D上关于 参数$\theta$ 的风险函数. $\alpha$ 是学习率,即每次迭代的步长,其值 必须合适,如果过大就不会收敛,过小则收敛太慢.

---

##### 提前停止

使用梯度下降法的过程中,由于过拟合的原因,会出现训练集拟合,但测试集不是最优. 故而可以使用验证集来对每次迭代的模型进行验证测试,并计算错误率. 如果在验证集上的错误率不再下降,就停止迭代, 防止过拟合.这就是$\color{red}{提前停止}$​策略.

---

##### 随机梯度下降法

在前面的梯度下降法的公式中,是对训练集全部样本进行损失函数的梯度计算(即批量梯度下降), 当训练集N很大时,每次迭代计算开销也很大.

那么可以使用随机梯度下降法.即不再对训练集整体进行迭代,而是每次迭代就从训练集中随机抽取一个样本,计算这个样本损失函数的梯度并更新参数.当经过足够次数的迭代,随机梯度下降也可以收敛到局部最优解.

那么参数更新到什么情况下就可以结束迭代呢?

由于是随机其中某个样本,而不是整体,所以当前样本梯度为0时,而其他梯度不等于0. 故而当模型在验证集上错误率不再下降时就可以停止迭代.

---

##### 小批量梯度下降法

小批量梯度是批量梯度与随机梯度的一个折中方法. 即每次抽取一小部分样本(K个)来计算梯度并更新参数.

K一般不会设置很大,通常在1-100之间,实际为了计算效率,通常是2的幂 $2^n$​ 

---

### 最小二乘法

设

- 模型为 $f(\pmb{x};\pmb{w},b) = \pmb{w}^T\pmb{x} + b$​ 
- $\pmb{w}$ 是权重向量 $\pmb{w}^T = [w_1, w_2,\dots,w_D]$
- $\pmb{x}$ 是特征向量 $\pmb{x}^T = [x_1,x_2,\dots,x_D]$​
- b 是偏置常量

$$
\pmb{w}^T\pmb{x} =[w_1, w_2,\dots,w_D]
\begin{bmatrix} 
x_1 \\ x_2\\ \vdots \\ x_D
\end{bmatrix} = c
\\
可令\; \hat{\pmb{x}} = 
\begin{bmatrix} 
\pmb{x} \\ 1
\end{bmatrix}=
\begin{bmatrix} 
x_1 \\ x_2\\ \vdots \\ x_D \\ 1
\end{bmatrix}; \;
\hat{\pmb{w}} = 
\begin{bmatrix} 
\pmb{w} \\ b
\end{bmatrix}=
\begin{bmatrix} 
w_1 \\ w_2\\ \vdots \\ w_D \\ b
\end{bmatrix}; \\
f(\pmb{x};\pmb{w},b) = f(\hat{\pmb{x}};\hat{\pmb{w}}) = \hat{\pmb{w}}^T\hat{\pmb{x}}\\
其中, \hat{\pmb{w}}^T\hat{\pmb{x}} = [\pmb{w}^T,b] 
\begin{bmatrix} 
\pmb{x} \\ 1 
\end{bmatrix}
= \pmb{w}^T\pmb{x} + b
$$

为了简化, 设 $f(\pmb{x};\pmb{w}) = \pmb{w}^T\pmb{x}$ ,那么经验风险为
$$
\Re(\pmb{w})=\frac{1}{N}\sum_{n=1}^N\mathcal{L}(y^{(n)},f(\pmb{x}^{(n)};\pmb{w}))\\
$$
注: $y^{(n)}$ 表示第n个样本的标签; $y_n$ 表示y向量中第n个维度的元素

为了简化, 省略 $\frac{1}{N}$ , 那么经验风险为: $\Re(\pmb{w})=\sum_{n=1}^N\mathcal{L}(y^{(n)},f(\pmb{x}^{(n)};\pmb{w}))$

设选择的损失函数为 平方损失函数,即 $\mathcal{L}(y^{(n)},f(\pmb{x}^{(n)};\pmb{w}))=\frac{1}{2}(y^{(n)},f(\pmb{x}^{(n)};\pmb{w}))^2$​

那么 $\Re(\pmb{w})=\sum_{n=1}^N\mathcal{L}(y^{(n)},f(\pmb{x}^{(n)};\pmb{w}))=\frac{1}{2}\sum_{n=1}^N(y^{(n)},\pmb{w}^T\pmb{x}^{(n)})^2$

由于 $\begin{Vmatrix}\pmb{x}\end{Vmatrix} = \sqrt{\begin{vmatrix}x_1\end{vmatrix}^2+\begin{vmatrix}x_2\end{vmatrix}^2+\cdots+\begin{vmatrix}x_n\end{vmatrix}^2} = \sqrt{\pmb{x}^T\pmb{x}}$​

则
$$
\begin{align}
\sum_{n=1}^N(y^{(n)},\pmb{w}^T\pmb{x}^{(n)})^2 
&=\begin{vmatrix}y^{(1)}-\pmb{w}^T\pmb{x}^{(1)}\end{vmatrix}^2+\cdots+
\begin{vmatrix}y^{(n)}-\pmb{w}^T\pmb{x}^{(n)}\end{vmatrix}^2\\
&=\begin{bmatrix} 
y^{(1)}-\pmb{w}^T\pmb{x}^{(1)} \\ \vdots \\
y^{(n)}-\pmb{w}^T\pmb{x}^{(n)}
\end{bmatrix}^T \cdot
\begin{bmatrix} 
y^{(1)}-\pmb{w}^T\pmb{x}^{(1)} \\ \vdots \\
y^{(n)}-\pmb{w}^T\pmb{x}^{(n)}
\end{bmatrix}\\
\end{align}
$$
又
$$
\begin{align}
\begin{bmatrix} 
y^{(1)}-\pmb{w}^T\pmb{x}^{(1)} \\ \vdots \\
y^{(n)}-\pmb{w}^T\pmb{x}^{(n)}
\end{bmatrix} &=
\begin{bmatrix}
y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(n)}
\end{bmatrix} - 
\begin{bmatrix}
\pmb{w}^T\pmb{x}^{(1)} \\ \pmb{w}^T\pmb{x}^{(2)}\\ \vdots \\ \pmb{w}^T\pmb{x}^{(n)}
\end{bmatrix} \\
&=\pmb{y} - \begin{bmatrix} 
{\pmb{x}^{(1)}}^T \\ \vdots \\ {\pmb{x}^{(n)}}^T
\end{bmatrix} \pmb{w}
\end{align}
$$
设矩阵
$$
\pmb{X} = \begin{bmatrix} 
\pmb{x_1}^{(1)} & \pmb{x_1}^{(2)} & \cdots & \pmb{x_1}^{(n)} \\
\vdots & \vdots & \ddots & \vdots \\
\pmb{x_n}^{(1)} & \pmb{x_n}^{(2)} & \cdots & \pmb{x_n}^{(n)}
\end{bmatrix}
$$
那么 $\Re(\pmb{w})=\frac{1}{2}\begin{Vmatrix}\pmb{y}-\pmb{X}^T\pmb{w}\end{Vmatrix}^2$, $\Re(\pmb{w})$ 是关于 $\pmb{w}$的凸函数, 因此 $\Re(\pmb{w})$ 的对 $\pmb{w}$ 的偏导为
$$
\begin{align}
\frac{\partial \; \Re(\pmb{w})}{\partial \pmb{w}} &= 
\frac{1}{2} \frac{\partial \begin{Vmatrix}\pmb{y}-\pmb{X}^T\pmb{w}\end{Vmatrix}^2}
{\partial \pmb{w}} \\ \\ &=
\frac{1}{2} \frac{\partial (\pmb{y}-\pmb{X}^T\pmb{w})^T(\pmb{y}-\pmb{X}^T\pmb{w})}
{\partial \pmb{w}} \\ \\ &=
\frac{1}{2} \frac{\partial (\pmb{y}-\pmb{X}^T\pmb{w})^T}{\partial \pmb{w}} \cdot
\frac{\partial (\pmb{y}-\pmb{X}^T\pmb{w})^T(\pmb{y}-\pmb{X}^T\pmb{w})}
{\partial (\pmb{y}-\pmb{X}^T\pmb{w})^T} \\ \\ &=
\frac{1}{2} \frac{\partial (\pmb{y}-\pmb{X}^T\pmb{w})^T}{\partial \pmb{w}} \cdot
2(\pmb{y}-\pmb{X}^T\pmb{w}) \\ \\ &=
\frac{\partial(\pmb{y}^T-\pmb{w}^T\pmb{X})}{\partial \pmb{w}} (\pmb{y}-\pmb{X}^T\pmb{w}) \\ \\ &=
- \frac{\partial \pmb{w}^T\pmb{X}}{\partial \pmb{w}} (\pmb{y}-\pmb{X}^T\pmb{w}) \\ \\ &=
- X(\pmb{y}-\pmb{X}^T\pmb{w})
\end{align}
$$

> [!NOTE]
>
> 矩阵微分
> $$
> \frac{\partial A^TX}{\partial X} = \frac{\partial X^T A}{\partial X} = A; \quad 特别地, \frac{\partial X^T X}{\partial X} = 2X \\
> $$
> 

要使凸函数最小, 则梯度为0 ,那么令 $\frac{\partial \Re(\pmb{w})}{\partial \pmb{w}} = 0$ 
$$
\begin{align}
即\quad -\pmb{X}(\pmb{y} - \pmb{X}^T\pmb{w}) &= 0\\ \\
\pmb{X}\pmb{y}=\pmb{X}\pmb{X}^T\pmb{w} \\ \\
\pmb{w} = (\pmb{X}\pmb{X}^T)^{-1}\pmb{X}\pmb{y}
\end{align}
$$
 可以看出 $\pmb{X}\pmb{X}^T$必须得存在逆矩阵,即$\pmb{X}$的行向量(特征向量) 之间是不相关的

那么如果遇到$\pmb{X}\pmb{X}^T$ 不可逆时, 需采取

- 使用 $\color{red}{主成分分析}$ 对数据进行预处理,消除不同特征之间的相关性
- 使用梯度下降法来估计

实际上, 为了防止过拟合,一般会对模型进行限制,即加入正则化项, $\Re(\pmb{w})=\frac{1}{2}\begin{Vmatrix}\pmb{y}-\pmb{X}^T\pmb{w}\end{Vmatrix}^2 + \frac{1}{2}\lambda \begin{Vmatrix} \pmb{w}\end{Vmatrix}^2$

那么 $\frac{\partial \; \Re(\pmb{w})}{\partial \pmb{w}}=-\pmb{X}(\pmb{y}-\pmb{X}^T\pmb{w}) + \lambda \pmb{w}$, 即 $\pmb{w} = (\pmb{X}\pmb{X}^T+\lambda\pmb{I})^{-1}\pmb{X}\pmb{y} $

可以看出, $\pmb{X}\pmb{X}^T$ 的主对角线元素都加上了一个常数 $\lambda$ 

这样$(\pmb{X}\pmb{X}^T+\lambda\pmb{I})$ 是必然满秩的,即$(\pmb{X}\pmb{X}^T+\lambda\pmb{I})$  存在逆矩阵

> [!NOTE]
>
> 这个$\lambda >0$是超参数,用于控制正则化的强度, 当$\lambda$ 增大, $(\pmb{X}\pmb{X}^T+\lambda\pmb{I})^{-1}$受 $\pmb{X}$ 的影响就下降

---



### 最大似然估计









## 线性模型







# 基础模型

## 前馈神经网络

## 卷积神经网络

## 循环神经网络

## 网络优化与正则化

## 注意力机制与外部记忆

## 无监督学习

## 模型独立的学习方式







# 进阶模型

## 概率图模型

## 深度信念网络

## 深度生成模型

## 深度强化学习

## 序列生成模型



# 常用符号表

| $ \mathbb{R}$ | 实数集 |
| ------------- | ------ |
|               |        |
|               |        |
|               |        |

